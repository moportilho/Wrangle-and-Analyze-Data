{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reporting: wragle_report\n",
    "* Create a **300-600 word written report** called \"wrangle_report.pdf\" or \"wrangle_report.html\" that briefly describes your wrangling efforts. This is to be framed as an internal document."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data wrangling is a crucial process in data analysis, involving the gathering, assessing, and cleaning of raw data to transform it into a structured and usable format. As a data enthusiast, I embarked on a challenging yet rewarding journey to wrangle messy data from various sources to unveil insights and correlations in the fascinating world of WeRateDogs. This report outlines the strategies and techniques employed during the data wrangling process.\n",
    "\n",
    "The data gathering phase involved multiple methods to collect the required data. I directly downloaded the WeRateDogs Twitter archive data from the CSV file, containing the dog ratings and additional details. The tweet image prediction data was retrieved using the Requests library from an online source in TSV format. Lastly, the Tweepy library was utilized to query additional data via the Twitter API, extracting essential tweet details such as retweet count and favorite count.\n",
    "\n",
    "The data assessment stage was critical in understanding the quality and tidiness issues present in the gathered data. A combination of visual and programmatic assessment techniques was employed. I detected and documented eight quality issues and two tidiness issues. These included missing data, incorrect data types, invalid dog names, retweets and non-original ratings, and duplicate tweet information.\n",
    "\n",
    "To address the identified issues, data cleaning was meticulously carried out. I made a copy of the original data to avoid any loss of information. I removed retweets and non-original ratings from the dataset to focus on original dog ratings with images. Invalid dog names were replaced with NaN, and rating denominators were standardized to 10. Duplicate tweets were also eliminated, ensuring a tidy and coherent dataset.\n",
    "\n",
    "A vital aspect of the wrangling process was merging the individual datasets to create a comprehensive master DataFrame. I merged the cleaned WeRateDogs Twitter archive with the tweet image prediction data using 'tweet_id' as the common key. This allowed for a comprehensive analysis of the dog ratings and image predictions. Additionally, I merged the master DataFrame with the extracted tweet details to incorporate retweet count and favorite count data.\n",
    "\n",
    "The data wrangling efforts bore fruitful insights. A compelling positive correlation was observed between retweet count and favorite count, indicating that highly retweeted dog ratings tended to receive more favorites, amplifying their popularity. Certain dog breeds, such as Golden Retrievers and Labradors, emerged as favorites among the Twitter community. Furthermore, engagement with WeRateDogs has steadily increased over time, reflecting the growing interest in adorable dogs on social media.\n",
    "\n",
    "Data wrangling is an essential process that lays the foundation for insightful data analysis. The journey of wrangling messy data from WeRateDogs involved strategic data gathering, rigorous assessment, and meticulous cleaning to produce a tidy and structured master DataFrame. This enabled the exploration of correlations between retweet count, favorite count, and dog breeds. The insights gained provide valuable information about user engagement, popular dog breeds, and the captivating world of WeRateDogs. The clean and processed data is now ready for further statistical analysis and visualization, unlocking the full potential of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from subprocess import call\n",
    "call(['python', '-m', 'nbconvert', 'wrangle_report.ipynb'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
